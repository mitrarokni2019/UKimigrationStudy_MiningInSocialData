{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12457a4c-a263-45b5-8443-80eb627ab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20ed009-8bfb-4f37-8b0e-87f162dabbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Custom Adjustments\n",
    "def custom_adjustments(text):\n",
    "    \"\"\"Custom text adjustments based on repository preprocessing.\"\"\"\n",
    "    # Remove hyphens and join hyphenated words\n",
    "    text = re.sub(r'(?<!\\w)-|-(?!\\w)', '', text)\n",
    "    \n",
    "    # Normalize possessives (e.g., \"immigrant's\" -> \"immigrant\")\n",
    "    text = re.sub(r\"'s\\b\", \"\", text)\n",
    "    \n",
    "    # Remove speaker names (if they exist in your dataset)\n",
    "    text = re.sub(r\"^\\[.*?\\]:\", \"\", text)  # Assuming speaker names are bracketed, e.g., \"[Speaker]:\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Step 2: Advanced Cleaning\n",
    "def advanced_clean_text(text):\n",
    "    \"\"\"Perform advanced text cleaning.\"\"\"\n",
    "    # Handle missing values\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Replace unwanted characters (e.g., numbers, punctuation, etc.)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)     # Replace multiple spaces with a single space\n",
    "    text = text.strip().lower()          # Convert to lowercase\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Step 3: Tokenization Using spaCy\n",
    "def tokenize_with_spacy(text):\n",
    "    \"\"\"Tokenize text using spaCy.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return tokens\n",
    "\n",
    "# Complete Preprocessing Pipeline\n",
    "def preprocess_pipeline(text):\n",
    "    \"\"\"Complete preprocessing pipeline.\"\"\"\n",
    "    # Step 1: Custom adjustments\n",
    "    adjusted_text = custom_adjustments(text)\n",
    "    \n",
    "    # Step 2: Advanced cleaning\n",
    "    cleaned_text = advanced_clean_text(adjusted_text)\n",
    "    \n",
    "    # Step 3: Tokenization\n",
    "    tokens = tokenize_with_spacy(cleaned_text)\n",
    "    \n",
    "    return cleaned_text, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a84eb77-c02c-466d-ba61-98f431a49ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>Party</th>\n",
       "      <th>cleaned_contents</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir J. Anderson</td>\n",
       "      <td>2/6/1940</td>\n",
       "      <td>Eire Citizens (Immigration)</td>\n",
       "      <td>I have had no representations from the police ...</td>\n",
       "      <td>Conservative Party</td>\n",
       "      <td>i have had no representations from the police ...</td>\n",
       "      <td>[representation, police, contrary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sir J. Anderson</td>\n",
       "      <td>2/6/1940</td>\n",
       "      <td>Eire Citizens (Immigration)</td>\n",
       "      <td>No, Sir. Even if the principle underlying the ...</td>\n",
       "      <td>Conservative Party</td>\n",
       "      <td>no sir even if the principle underlying the ri...</td>\n",
       "      <td>[sir, principle, underlie, right, hon, gentlem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. M. MacDonald</td>\n",
       "      <td>2/14/1940</td>\n",
       "      <td>Palestine (Jewish Immigration)</td>\n",
       "      <td>The steady improvement in the internal situati...</td>\n",
       "      <td>Labour Party</td>\n",
       "      <td>the steady improvement in the internal situati...</td>\n",
       "      <td>[steady, improvement, internal, situation, pal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr. MacDonald</td>\n",
       "      <td>2/14/1940</td>\n",
       "      <td>Palestine (Jewish Immigration)</td>\n",
       "      <td>The legal quota allowed something over 10,000 ...</td>\n",
       "      <td>Labour Party</td>\n",
       "      <td>the legal quota allowed something over jews to...</td>\n",
       "      <td>[legal, quota, allow, jews, settle, palestine,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr. MacDonald</td>\n",
       "      <td>2/14/1940</td>\n",
       "      <td>Palestine (Jewish Immigration)</td>\n",
       "      <td>That is another question.</td>\n",
       "      <td>Labour Party</td>\n",
       "      <td>that is another question</td>\n",
       "      <td>[question]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            speaker       date                           title  \\\n",
       "0   Sir J. Anderson   2/6/1940     Eire Citizens (Immigration)   \n",
       "1   Sir J. Anderson   2/6/1940     Eire Citizens (Immigration)   \n",
       "2  Mr. M. MacDonald  2/14/1940  Palestine (Jewish Immigration)   \n",
       "3     Mr. MacDonald  2/14/1940  Palestine (Jewish Immigration)   \n",
       "4     Mr. MacDonald  2/14/1940  Palestine (Jewish Immigration)   \n",
       "\n",
       "                                            contents               Party  \\\n",
       "0  I have had no representations from the police ...  Conservative Party   \n",
       "1  No, Sir. Even if the principle underlying the ...  Conservative Party   \n",
       "2  The steady improvement in the internal situati...        Labour Party   \n",
       "3  The legal quota allowed something over 10,000 ...        Labour Party   \n",
       "4                          That is another question.        Labour Party   \n",
       "\n",
       "                                    cleaned_contents  \\\n",
       "0  i have had no representations from the police ...   \n",
       "1  no sir even if the principle underlying the ri...   \n",
       "2  the steady improvement in the internal situati...   \n",
       "3  the legal quota allowed something over jews to...   \n",
       "4                           that is another question   \n",
       "\n",
       "                                              tokens  \n",
       "0                 [representation, police, contrary]  \n",
       "1  [sir, principle, underlie, right, hon, gentlem...  \n",
       "2  [steady, improvement, internal, situation, pal...  \n",
       "3  [legal, quota, allow, jews, settle, palestine,...  \n",
       "4                                         [question]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'newdata/cleaned_data_7.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Apply preprocessing pipeline\n",
    "df[['cleaned_contents', 'tokens']] = df['contents'].fillna(\"\").apply(\n",
    "    lambda x: pd.Series(preprocess_pipeline(x))\n",
    ")\n",
    "\n",
    "# Save results to a new file for further use\n",
    "df.to_csv(\"newdata/preprocessed_data.csv\", index=False)\n",
    "\n",
    "# Check the result\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef4854-baf7-4511-9f97-70f2e6c05b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b287b6b-bff5-480e-8e79-fda168203a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e702184-d512-4129-98f3-1c029977e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from frame_terms import frame_words  # Assuming you saved this correctly\n",
    "from group_terms import countries  # Assuming you saved this correctly\n",
    "\n",
    "# Step 1: Match Frames\n",
    "def match_frames(tokens):\n",
    "    \"\"\"Match tokens to frame terms and count occurrences.\"\"\"\n",
    "    frame_counts = Counter()\n",
    "    for frame, terms in frame_words.items():\n",
    "        frame_counts[frame] = sum(1 for token in tokens if token in terms)\n",
    "    return frame_counts\n",
    "\n",
    "# Step 2: Match Countries\n",
    "def match_countries(text):\n",
    "    \"\"\"Identify countries or groups mentioned in the text.\"\"\"\n",
    "    matched_countries = []\n",
    "    for country, terms in countries.items():\n",
    "        if any(term.lower() in text for term in terms):\n",
    "            matched_countries.append(country)\n",
    "    return \", \".join(matched_countries) if matched_countries else \"None\"\n",
    "\n",
    "# Step 3: Apply Matching Functions\n",
    "def analyze_frames_and_groups(df):\n",
    "    \"\"\"Analyze frames and groups in the dataset.\"\"\"\n",
    "    # Add new columns for frame counts and matched countries\n",
    "    df['frame_counts'] = df['tokens'].apply(match_frames)\n",
    "    df['matched_countries'] = df['cleaned_contents'].apply(match_countries)\n",
    "    return df\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "#file_path = 'newdata/new_final_data.csv'\n",
    "#df = pd.read_csv(file_path)\n",
    "\n",
    "# Analyze Frames and Countries\n",
    "df = analyze_frames_and_groups(df)\n",
    "\n",
    "# Save Results\n",
    "#output_path = 'analyzed_frames_groups.csv'\n",
    "#df.to_csv(output_path, index=False)\n",
    "\n",
    "#print(f\"Analyzed data saved to {output_path}\")\n",
    "\n",
    "# Preview the result\n",
    "print(df[['speaker', 'date', 'title', 'party', 'frame_counts', 'matched_countries']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48432711-6437-460c-8be9-b38780ecaea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10c536-824d-4f82-9969-9c84e0821db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
